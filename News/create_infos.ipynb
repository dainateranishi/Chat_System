{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import random\n",
    "from pyknp import KNP\n",
    "import sys\n",
    "import emoji\n",
    "import re\n",
    "import neologdn\n",
    "\n",
    "key = \"1cc54f894659430f86ac6c1686a63c90\"\n",
    "info_elements =[\"who\", \"do\", \"what\", \"when\", \"where\", \"how\", \"whose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headlines(_category):\n",
    "    newsapi = NewsApiClient(api_key=key)\n",
    "    headlines = newsapi.get_top_headlines(category= _category, country='jp')\n",
    "    if( headlines['totalResults'] > 0 ):\n",
    "        pass\n",
    "        #print(headlines[\"totalResults\"])\n",
    "    else:\n",
    "        print(\"条件に合致したトップニュースはありません。\")\n",
    "        \n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category = {business、entertainment、general、health、science、sports、technology}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ramdom_news(headlines):\n",
    "    news = []\n",
    "    for headline in headlines['articles']:\n",
    "        news.append((headline[\"title\"], headline[\"description\"]))\n",
    "\n",
    "    kiji = random.choice(news)\n",
    "    \n",
    "   # o_kiji.append(kiji) #デバッグ用\n",
    "\n",
    "    midashi = clean_sentence(kiji[0].split(\"-\")[0])\n",
    "\n",
    "\n",
    "    #utterance = \"最近のニュースでは「\" + midashi + \"」だそうです。\\n\"\n",
    "\n",
    "    #print(utterance)\n",
    "    \n",
    "    try:\n",
    "        sentences = []\n",
    "        lines = kiji[1].split(\"。\")\n",
    "        for line in lines:\n",
    "            sentences.append(clean_sentence(line))\n",
    "    except:\n",
    "        sentences = kiji[1]\n",
    "    \n",
    "    return midashi,sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_normalization_representative_notation(fstring):\n",
    "    \"\"\" 正規化代表表記を抽出します\n",
    "    \"\"\"\n",
    "    begin = fstring.find('正規化代表表記:')\n",
    "    end = fstring.find(\">\", begin+1)\n",
    "    daihyous = fstring[begin + len('正規化代表表記:') : end].split(\"/\")\n",
    "    sentence = daihyous[0]\n",
    "    for daihyou in daihyous[1:]:\n",
    "        if(daihyou.find(\"+\") != -1):\n",
    "            sentence += daihyou.split(\"+\")[1]\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dependency_structure(line):\n",
    "    \"\"\"係り受け構造を抽出します\n",
    "    \"\"\"\n",
    "\n",
    "    # KNP\n",
    "    knp = KNP(option = '-tab -anaphora')\n",
    "\n",
    "    # 解析\n",
    "    result = knp.parse(line)\n",
    "\n",
    "    # 文節リスト\n",
    "    bnst_list = result.bnst_list()\n",
    "\n",
    "    # 文節リストをidによるディクショナリ化する\n",
    "    bnst_dic = dict((x.bnst_id, x) for x in bnst_list)\n",
    "\n",
    "    tuples = []\n",
    "    for bnst in bnst_list:\n",
    "        if bnst.parent_id != -1:\n",
    "            # (from, to)\n",
    "            print(\"bnst_id:{} parent_id:{}\\n\".format(bnst.bnst_id, bnst.parent_id))\n",
    "            tuples.append((select_normalization_representative_notation(bnst.fstring), select_normalization_representative_notation(bnst_dic[bnst.parent_id].fstring)))\n",
    "\n",
    "    return tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gimonshi(bnst, bnst_dic):\n",
    "    \n",
    "    fstring = bnst.fstring\n",
    "    #ノ格\n",
    "    if fstring.find(\"ノ格\") != -1:\n",
    "        if (fstring.find(\"組織名\") != -1 or fstring.find(\"組織名疑\") != -1 or fstring.find(\"地名\") != -1 or fstring.find(\"地名疑\") != -1): \n",
    "            return \"where\"\n",
    "                \n",
    "        elif (fstring.find(\"人\") != -1 or fstring.find(\"人名\") != -1):\n",
    "            if bnst_dic[bnst.parent_id].fstring.find(\"用言:動\"):\n",
    "                return \"who\"\n",
    "            else:\n",
    "                return \"whose\"\n",
    "            \n",
    "        elif(fstring.find(\"時間\") != -1 and fstring.find(\"SM-主体\") == -1):\n",
    "            return \"when\"\n",
    "        \n",
    "    #ガ格\n",
    "    elif fstring.find(\"ガ格\") != -1:\n",
    "        if (fstring.find(\"人\") != -1 or fstring.find(\"人名\") != -1):\n",
    "            return \"who\"\n",
    "        else:\n",
    "            return \"what\"\n",
    "        \n",
    "        \n",
    "    #ヲ格\n",
    "    elif fstring.find(\"ヲ格\") != -1:\n",
    "        return \"what\"\n",
    "            \n",
    "    #二格\n",
    "    elif fstring.find(\"ニ格\") != -1:\n",
    "        if (fstring.find(\"時間\") != -1 and fstring.find(\"SM-主体\") == -1):\n",
    "            return \"when\"\n",
    "        elif (fstring.find(\"組織名\") != -1 or fstring.find(\"組織名疑\") != -1 or fstring.find(\"地名\") != -1 or fstring.find(\"地名疑\") != -1): \n",
    "            return \"where\"\n",
    "        elif (fstring.find(\"人\") != -1 or fstring.find(\"人名\") != -1):\n",
    "            return \"who\"\n",
    "        else:\n",
    "            return \"what\"\n",
    "        \n",
    "    #へ格\n",
    "    elif fstring.find(\"ヘ格\") != -1:\n",
    "        if (fstring.find(\"組織名\") != -1 or fstring.find(\"組織名疑\") != -1 or fstring.find(\"地名\") != -1 or fstring.find(\"地名疑\") != -1): \n",
    "            return \"where\"\n",
    "        else:\n",
    "            return \"what\"\n",
    "        \n",
    "    #ト格\n",
    "    elif fstring.find(\"ト格\") != -1:\n",
    "        if (fstring.find(\"人\") != -1 or fstring.find(\"人名\") != -1):\n",
    "            return \"who\"\n",
    "        else:\n",
    "            return \"what\"\n",
    "                \n",
    "    #デ格\n",
    "    elif fstring.find(\"デ格\") != -1:\n",
    "        if (fstring.find(\"組織名\") != -1 or fstring.find(\"組織名疑\") != -1 or fstring.find(\"地名\") != -1 or fstring.find(\"地名疑\") != -1): \n",
    "            return \"where\"\n",
    "        elif bnst_dic[bnst.parent_id].fstring.find(\"用言:動\") != -1:\n",
    "                return \"how\"\n",
    "                \n",
    "        \n",
    "     #ハ\n",
    "    elif fstring.find(\"<ハ>\") != -1:\n",
    "        if (fstring.find(\"組織名\") != -1 or fstring.find(\"組織名疑\") != -1 or fstring.find(\"地名\") != -1 or fstring.find(\"地名疑\") != -1): \n",
    "            return \"where\"\n",
    "        else:\n",
    "            return \"who\"\n",
    "        \n",
    "    #述語\n",
    "    elif fstring.find(\"用言:動\") != -1:\n",
    "            return \"do\"\n",
    "        \n",
    "    #無格\n",
    "    elif fstring.find(\"無格\") != -1:\n",
    "        if(fstring.find(\"時間\") != -1 and fstring.find(\"SM-主体\") == -1):\n",
    "            return \"when\"\n",
    "        elif(fstring.find(\"組織名\") != -1 or fstring.find(\"組織名疑\") != -1  or fstring.find(\"地名\") != -1 or fstring.find(\"地名疑\") != -1): \n",
    "            return \"where\"\n",
    "        \n",
    "    #形容詞\n",
    "    elif fstring.find(\"用言:形\") != -1:\n",
    "        return \"how\"\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_knowledge(sentence):\n",
    "    ##knpで解析\n",
    "    knp = KNP(option = '-tab -anaphora')\n",
    "    result = knp.parse(sentence.replace(\" \", \"\"))\n",
    "    bnst_list = result.bnst_list()\n",
    "\n",
    "    #文節辞書\n",
    "    bnst_dic = dict((x.bnst_id, x) for x in bnst_list)\n",
    "\n",
    "    infos = []\n",
    "    info = dict((x, None) for x in info_elements)\n",
    "    for bnst in bnst_list:\n",
    "        place = get_gimonshi(bnst, bnst_dic)\n",
    "        \n",
    "        if(place == None):\n",
    "            pass\n",
    "        \n",
    "        elif info[place] == None:\n",
    "            info[place] = select_normalization_representative_notation(bnst.fstring)\n",
    "            \n",
    "        else:\n",
    "            infos.append(info)\n",
    "            del info\n",
    "            info = dict((x, None) for x in info_elements)\n",
    "            info[place] = select_normalization_representative_notation(bnst.fstring)\n",
    "    \n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_infos(topic):\n",
    "    all_infos = []\n",
    "    midashi, sentences = get_ramdom_news(get_headlines(topic))\n",
    "    \n",
    "    for i, line in enumerate(sentences):\n",
    "        print(line + \"\\n\")\n",
    "        infos = generate_knowledge(line)\n",
    "        for info in infos:\n",
    "            all_infos.append(info)\n",
    "    \n",
    "    return midashi,all_infos,sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(\"[(].*?[)]\", \"\", sentence)\n",
    "    sentence = re.sub(\"[（].*?[）]\", \"\", sentence)\n",
    "    sentence = re.sub(re.compile(\"[!-/:-@[-`{-~]\"), '', sentence)\n",
    "    sentence_without_emoji = \"\".join([\"\" if c in emoji.UNICODE_EMOJI else c for c in sentence])\n",
    "    tmp = re.sub(r'(\\d)([,.])(\\d+)', r'\\1\\3', sentence_without_emoji)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def confirm_parent_bnst(sentence):\n",
    "    line = sentence.replace(\" \",\"\").replace(\"　\",\"\")\n",
    "    tuples = select_dependency_structure(line)\n",
    "    for t in tuples:\n",
    "        print(t[0] + ' => ' + t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
